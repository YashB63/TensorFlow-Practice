{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "          76,   80,   84,   88,   92,   96])>,\n",
       " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(-100, 100, 4)\n",
    "\n",
    "y = X + 10\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:40]\n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:]\n",
    "y_test = y[40:]\n",
    "\n",
    "X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Our Models\n",
    "\n",
    "    Saving our models allows us to use them outside of VSCode, Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
    "\n",
    "    There are two main formats we can save our models too:\n",
    "\n",
    "    1. The SaveModel format\n",
    "    2. The HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 41.4072 - mae: 41.4072\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 31.5937 - mae: 31.5937\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 36.8485 - mae: 36.8485\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.4012 - mae: 26.4012\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.4818 - mae: 14.4818\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5745 - mae: 11.5745\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6402 - mae: 12.6402\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0509 - mae: 11.0509\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 39.7576 - mae: 39.7576\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.2430 - mae: 27.2430\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0336 - mae: 11.0336\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.4211 - mae: 24.4211\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.3237 - mae: 19.3237\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.5689 - mae: 23.5689\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6805 - mae: 15.6805\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4059 - mae: 10.4059\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.5959 - mae: 19.5959\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.2478 - mae: 13.2478\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9998 - mae: 15.9998\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1850 - mae: 10.1850\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.7213 - mae: 13.7213\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.8997 - mae: 21.8997\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4648 - mae: 10.4648\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.7635 - mae: 15.7635\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9111 - mae: 14.9111\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.5470 - mae: 19.5470\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.4882 - mae: 20.4882\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8720 - mae: 14.8720\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2646 - mae: 9.2646\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.2237 - mae: 30.2237\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 54.9011 - mae: 54.9011\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6726 - mae: 9.6726\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.2785 - mae: 12.2785\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.3379 - mae: 24.3379\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9743 - mae: 11.9743\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.2451 - mae: 22.2451\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3287 - mae: 17.3287\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6525 - mae: 10.6525\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1686 - mae: 11.1686\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9295 - mae: 17.9295\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3805 - mae: 10.3805\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2768 - mae: 7.2768\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.8965 - mae: 18.8965\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.0392 - mae: 20.0392\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1034 - mae: 10.1034\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3540 - mae: 11.3540\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8335 - mae: 9.8335\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6379 - mae: 17.6379\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3176 - mae: 9.3176\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3514 - mae: 13.3514\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4259 - mae: 11.4259\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.3281 - mae: 29.3281\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.7093 - mae: 16.7093\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.6766 - mae: 21.6766\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.1175 - mae: 22.1175\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2251 - mae: 11.2251\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1965 - mae: 13.1965\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8599 - mae: 9.8599\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3837 - mae: 13.3837\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9228 - mae: 10.9228\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.5371 - mae: 13.5371\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.6027 - mae: 17.6027\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1941 - mae: 9.1941\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.4697 - mae: 18.4697\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1492 - mae: 10.1492\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.3465 - mae: 24.3465\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9298 - mae: 10.9298\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8035 - mae: 10.8035\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.3293 - mae: 23.3293\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8098 - mae: 8.8098\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9637 - mae: 15.9637\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1422 - mae: 8.1422\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4669 - mae: 9.4669\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.1405 - mae: 28.1405\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2272 - mae: 10.2272\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1799 - mae: 13.1799\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4301 - mae: 18.4301\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0343 - mae: 9.0343\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.4747 - mae: 23.4747\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.1538 - mae: 26.1538\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4219 - mae: 11.4219\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4887 - mae: 12.4887\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.1763 - mae: 17.1763\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.6043 - mae: 6.6043\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.3178 - mae: 20.3178\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1852 - mae: 10.1852\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.3561 - mae: 24.3561\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0203 - mae: 19.0203\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1767 - mae: 7.1767\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.2609 - mae: 18.2609\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3119 - mae: 13.3119\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7262 - mae: 8.7262\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1766 - mae: 14.1766\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.1772 - mae: 17.1772\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7531 - mae: 16.7531\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1213 - mae: 11.1213\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.1696 - mae: 21.1696\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5125 - mae: 10.5125\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6093 - mae: 14.6093\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7829 - mae: 17.7829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x185e0d99310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's build a model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(tf.expand_dims(X_train, axis= -1), y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model using the SavedModel format\n",
    "model_2.save(\"best_model_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using HDF5 format\n",
    "model_2.save(\"best_model_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31 (124.00 Byte)\n",
      "Trainable params: 31 (124.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
